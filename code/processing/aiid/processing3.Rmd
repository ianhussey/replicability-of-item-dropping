---
title: "Assessing the replicability of recommendations of Cronbach's-alpha-if-item-removed"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

Outputs are data frames containing the drop decisions for analysis.

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(psych)
library(furrr)
library(janitor)
library(ggpp)

# functions
# rounds all numeric variables in a dataframe to the desired number of places. Non-numeric variables will be ignored.
round_df <- function(df, digits) {
  mutate_if(df, is.numeric, janitor::round_half_up, digits = 2)
}

# set up parallel processing
future::plan(multisession)

# set seed for reproducibility
set.seed(42)

```

# Data

```{r}

data_nested_single_timepoint <- read_rds("../../../data/processed/aiid/data_nested_single_timepoint.rds")

n_replications <- 5000L

```

N replications = `r n_replications`

# Create nested pairs of samples of data from each scale

```{r}

if(file.exists("../../../data/processed/aiid/data_nested_single_timepoint_25.rds") & 
   file.exists("../../../data/processed/aiid/data_nested_single_timepoint_50.rds") & 
   file.exists("../../../data/processed/aiid/data_nested_single_timepoint_100.rds") & 
   file.exists("../../../data/processed/aiid/data_nested_single_timepoint_250.rds") & 
   file.exists("../../../data/processed/aiid/data_nested_single_timepoint_500.rds")){
  
  data_nested_single_timepoint_25 <- 
    read_rds("../../../data/processed/aiid/data_nested_single_timepoint_25.rds")
  
  data_nested_single_timepoint_50 <- 
    read_rds("../../../data/processed/aiid/data_nested_single_timepoint_50.rds")
  
  data_nested_single_timepoint_100 <- 
    read_rds("../../../data/processed/aiid/data_nested_single_timepoint_100.rds")
  
  data_nested_single_timepoint_250 <- 
    read_rds("../../../data/processed/aiid/data_nested_single_timepoint_250.rds")
  
  data_nested_single_timepoint_500 <- 
    read_rds("../../../data/processed/aiid/data_nested_single_timepoint_500.rds")
  
} else {
  
  generate_replications <- function(input_data, n_replications, subset_n_per_split){
    
    helper_subset_n <- function(dat, subset_n_per_split){sample_n(dat, size = subset_n_per_split*2)}
    
    res <- 
      tibble(replication = seq(from = 1, to = n_replications, by = 1)) |>
      mutate(nest(mutate(input_data, id = row_number()), data = everything()),
             data_subset   = map(data, helper_subset_n, subset_n_per_split = subset_n_per_split),
             data_subset_a = map(data_subset, sample_frac, size = 0.5),
             data_subset_b = map2(data_subset, data_subset_a, anti_join, by = "id"),
             data_subset_a = map(data_subset_a, select, -id),
             data_subset_b = map(data_subset_b, select, -id)) |>
      select(-data, -data_subset)
    
    return(res)
  }
  
  data_nested_single_timepoint_25 <- data_nested_single_timepoint |>
    mutate(replications = furrr::future_map(data, 
                                            generate_replications, 
                                            n_replications = n_replications, 
                                            subset_n_per_split = 25,
                                            .options = furrr_options(seed = TRUE)),
           subset_n_per_split = 25) |>
    select(-data) |>
    unnest(replications)
  
  data_nested_single_timepoint_50 <- data_nested_single_timepoint |>
    mutate(replications = furrr::future_map(data, 
                                            generate_replications, 
                                            n_replications = n_replications, 
                                            subset_n_per_split = 50,
                                            .options = furrr_options(seed = TRUE)),
           subset_n_per_split = 50) |>
    select(-data) |>
    unnest(replications)
  
  data_nested_single_timepoint_100 <- data_nested_single_timepoint |>
    mutate(replications = furrr::future_map(data, 
                                            generate_replications,
                                            n_replications = n_replications,
                                            subset_n_per_split = 100,
                                            .options = furrr_options(seed = TRUE)),
           subset_n_per_split = 100) |>
    select(-data) |>
    unnest(replications)
  
  data_nested_single_timepoint_250 <- data_nested_single_timepoint |>
    mutate(replications = furrr::future_map(data, 
                                            generate_replications,
                                            n_replications = n_replications,
                                            subset_n_per_split = 250,
                                            .options = furrr_options(seed = TRUE)),
           subset_n_per_split = 250) |>
    select(-data) |>
    unnest(replications)
  
  data_nested_single_timepoint_500 <- data_nested_single_timepoint |>
    mutate(replications = furrr::future_map(data, 
                                            generate_replications,
                                            n_replications = n_replications, 
                                            subset_n_per_split = 500,
                                            .options = furrr_options(seed = TRUE)),
           subset_n_per_split = 500) |>
    select(-data) |>
    unnest(replications)
  
  # save individual objects to disk
  write_rds(data_nested_single_timepoint_25, 
            "../../../data/processed/aiid/data_nested_single_timepoint_25.rds", 
            compress = "gz")
  
  write_rds(data_nested_single_timepoint_50, 
            "../../../data/processed/aiid/data_nested_single_timepoint_50.rds", 
            compress = "gz")
  
  write_rds(data_nested_single_timepoint_100, 
            "../../../data/processed/aiid/data_nested_single_timepoint_100.rds", 
            compress = "gz")
  
  write_rds(data_nested_single_timepoint_250, 
            "../../../data/processed/aiid/data_nested_single_timepoint_250.rds", 
            compress = "gz")
  
  write_rds(data_nested_single_timepoint_500, 
            "../../../data/processed/aiid/data_nested_single_timepoint_500.rds", 
            compress = "gz")
  
}

```

# Drop decisions

```{r}

if(file.exists("../../../data/processed/aiid/data_drop_decisions.rds")){
  
  data_drop_decisions <- read_rds("../../../data/processed/aiid/data_drop_decisions.rds")
  
} else {
  
  item_to_drop_cronbach <- function(data){
    
    res <- psych::alpha(data)
    
    alpha_full_scale <- as.numeric(res$total["raw_alpha"])
    
    res$alpha.drop |>
      as_tibble(rownames = "item") |>
      filter(raw_alpha == max(raw_alpha)) |>
      select(item_to_drop = item, 
             alpha_if_dropped = raw_alpha) |>
      mutate(alpha_full_scale = alpha_full_scale,
             item_to_drop_or_none = ifelse(alpha_full_scale >= alpha_if_dropped, "none", item_to_drop))
  }
  
  # alpha_if_given_item_dropped <- function(data, item_to_drop){
  #   
  #   res <- data |>
  #     select(-{{item_to_drop}}) |>
  #     psych::alpha()
  #   
  #   alpha <- as.numeric(res$total["raw_alpha"])
  #   
  #   return(alpha)
  # }
  
  
  item_to_drop_random <- function(data){
    
    item_to_drop <- data |>
      colnames() |>
      sample(1)
    
    res <- data |>
      select(-{{item_to_drop}}) |>
      psych::alpha()
    
    alpha <- as.numeric(res$total["raw_alpha"])
    
    results <- tibble(random_item_to_drop = item_to_drop, 
                      alpha_if_random_dropped = alpha)
    
    return(results)
  }
  
  
  item_to_drop_full_scale_correlation <- function(data){
    
    dat <- data |>
      rownames_to_column(var = "id")
    
    mean_scores <- dat |>
      pivot_longer(cols = -id,
                   names_to = "item",
                   values_to = "response") |>
      group_by(id) |>
      summarize(mean_score = mean(response), .groups = "drop")
    
    dat_with_sum_scores <- 
      full_join(mean_scores, dat, by = "id") |>
      select(-id)
    
    data.frame(r = cor(dat_with_sum_scores)[1,]) |>
      rownames_to_column(var = "item") |>
      filter(item != "mean_score") |>
      arrange(r) |>
      slice(1:1) |>
      select(item_to_drop_fullscalecorrelation = item)
  }
  
  
  drop_decisions_workflow <- function(data){
    
    data |>
      # subset A
      mutate(alpha_a = furrr::future_map(data_subset_a, 
                                         item_to_drop_cronbach,
                                         .options = furrr_options(seed = TRUE))) |>
      unnest(alpha_a) |>
      rename(item_to_drop_a         = item_to_drop,
             item_to_drop_or_none_a = item_to_drop_or_none,
             alpha_if_dropped_a     = alpha_if_dropped,
             alpha_full_scale_a     = alpha_full_scale) |>
      # subset B
      mutate(alpha_b = furrr::future_map(data_subset_b,
                                         item_to_drop_cronbach,
                                         .options = furrr_options(seed = TRUE))) |>
      unnest(alpha_b) |>
      rename(item_to_drop_b         = item_to_drop,
             item_to_drop_or_none_b = item_to_drop_or_none,
             alpha_if_dropped_b     = alpha_if_dropped,
             alpha_full_scale_b     = alpha_full_scale) |>
      # compare
      mutate(match_item_if_dropped_cronbach = item_to_drop_a == item_to_drop_b,
             match_item_if_dropped_or_none_cronbach = item_to_drop_or_none_a == item_to_drop_or_none_b) |>
      #   # # out of sample comparisons
      #   # |>
      #   #   mutate(alpha_if_a_recommendation_dropped_b = 
      #   #            furrr::future_map2(data_subset_b, 
      #   #                               item_to_drop_a,
      #   #                               alpha_if_given_item_dropped,
      #   #                               .options = furrr_options(seed = TRUE))) |>
      #   #   mutate(alpha_if_a_recommendation_dropped_b = as.numeric(alpha_if_a_recommendation_dropped_b),
      #   #          alpha_b_diff = alpha_full_scale_b - alpha_if_a_recommendation_dropped_b,
      #   #          alpha_b_improved = alpha_b_diff > 0)
      # alpha if random item dropped
      mutate(alpha_random_a = furrr::future_map(data_subset_a,
                                                item_to_drop_random,
                                                .options = furrr_options(seed = TRUE))) |>
      unnest(alpha_random_a) |>
      rename(item_to_drop_random_a     = random_item_to_drop,
             alpha_if_random_dropped_a = alpha_if_random_dropped) |>
      # subset B
      mutate(alpha_random_b = furrr::future_map(data_subset_b,
                                                item_to_drop_random,
                                                .options = furrr_options(seed = TRUE))) |>
      unnest(alpha_random_b) |>
      rename(item_to_drop_random_b     = random_item_to_drop,
             alpha_if_random_dropped_b = alpha_if_random_dropped) |>
      # compare
      mutate(match_item_if_dropped_random = item_to_drop_random_a == item_to_drop_random_b) |>

      # drop recommendation based on correlation item with lowset correlation with full scale 
      mutate(fullscalecorrelation_a = furrr::future_map(data_subset_a,
                                                        item_to_drop_full_scale_correlation,
                                                        .options = furrr_options(seed = TRUE))) |>
      unnest(fullscalecorrelation_a) |>
      rename(item_to_drop_fullscalecorrelation_a = item_to_drop_fullscalecorrelation) |>
      mutate(fullscalecorrelation_b = furrr::future_map(data_subset_b,
                                                        item_to_drop_full_scale_correlation,
                                                        .options = furrr_options(seed = TRUE))) |>
      unnest(fullscalecorrelation_b) |>
      rename(item_to_drop_fullscalecorrelation_b = item_to_drop_fullscalecorrelation) |>
      # compare
      mutate(match_item_if_dropped_fullscalecorrelation = item_to_drop_fullscalecorrelation_a == item_to_drop_fullscalecorrelation_b,
             match_cronbach_fullscalecorrelation_a = item_to_drop_fullscalecorrelation_a == item_to_drop_a,
             match_cronbach_fullscalecorrelation_b = item_to_drop_fullscalecorrelation_b == item_to_drop_b) |>
      
      # drop data columns
      select(-data_subset_a, -data_subset_b)
  }
  
  # fit in batches given that data_replications are very large objects
    # temp  <- data_nested_single_timepoint_25 |>
    #   slice(1:1000) |>
    #   drop_decisions_workflow()
    # 
    # mean(temp$match_item_if_dropped_cronbach)
    # mean(temp$match_item_if_dropped_or_none_cronbach)
    # mean(temp$match_item_if_dropped_random)
    # mean(temp$match_item_if_dropped_fullscalecorrelation)
    # mean(temp$match_cronbach_fullscalecorrelation_a)
    # mean(temp$match_cronbach_fullscalecorrelation_b)


  
  data_drop_decisions_25  <- drop_decisions_workflow(data_nested_single_timepoint_25)
  data_drop_decisions_50  <- drop_decisions_workflow(data_nested_single_timepoint_50)
  data_drop_decisions_100 <- drop_decisions_workflow(data_nested_single_timepoint_100)
  data_drop_decisions_250 <- drop_decisions_workflow(data_nested_single_timepoint_250)
  data_drop_decisions_500 <- drop_decisions_workflow(data_nested_single_timepoint_500)
  
  # write to disk
  write_rds(data_drop_decisions_25, 
            "../../../data/processed/aiid/data_drop_decisions_25.rds", 
            compress = "gz")
  
  write_rds(data_drop_decisions_50, 
            "../../../data/processed/aiid/data_drop_decisions_50.rds", 
            compress = "gz")
  
  write_rds(data_drop_decisions_100, 
            "../../../data/processed/aiid/data_drop_decisions_100.rds", 
            compress = "gz")
  
  write_rds(data_drop_decisions_250, 
            "../../../data/processed/aiid/data_drop_decisions_250.rds", 
            compress = "gz")
  
  # combine
  data_drop_decisions <- 
    bind_rows(data_drop_decisions_25,
              data_drop_decisions_50,
              data_drop_decisions_100,
              data_drop_decisions_250,
              data_drop_decisions_500)
  
  write_rds(data_drop_decisions, 
            "../../../data/processed/aiid/data_drop_decisions.rds", 
            compress = "gz")
  
}

```

# Session info

```{r}

sessionInfo()

```

