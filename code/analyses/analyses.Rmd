---
title: "Assessing the replicability of item dropping"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

```{r}

# dependencies
library(tidyverse)
#library(lavaan)
#library(semTools)
library(knitr)
library(kableExtra)
#library(moments)
#library(plotrix)
#library(lubridate)
library(psych)
library(furrr)
library(lme4)
library(sjPlot)
library(emmeans)
#library(ggstance)
library(janitor)
library(boot)

# create necessary directories
dir.create("../../data/results")

# functions
# rounds all numeric variables in a dataframe to the desired number of places. Non-numeric variables will be ignored.
round_df <- function(df, digits) {
  mutate_if(df, is.numeric, janitor::round_half_up, digits = 2)
}

# set up parallel processing
future::plan(multisession)

# set seed for reproducibility
set.seed(42)

```

# Data

```{r}

#data_first_timepoint <- read_rds("../../data/processed/data_first_timepoint.rds")
data_nested_single_timepoint <- read_rds("../../data/processed/data_nested_single_timepoint.rds")

```

# Internal consistency

## Check full sample metrics

```{r}

cronbachs_alpha <- function(data){
  psych::alpha(data)$total["raw_alpha"]
}

results_overall <- data_nested_single_timepoint |> 
  mutate(results = furrr::future_map(data, 
                                     cronbachs_alpha, 
                                     .options = furrr_options(seed = TRUE))) |>
  unnest(results)

results_overall |>
  select(scale, alpha = raw_alpha) |>
  round_df(2) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Analysis

```{r}

if(file.exists("../../data/results/results_nested.rds")){
  
  results_nested <- read_rds("../../data/results/results_nested.rds")
  
} else {
  
  # assess which item, if dropped, would result in the highest alpha in the remaining items
  item_to_delete_to_max_alpha <- function(data){
    
    res <- psych::alpha(data)
    
    alpha_full_scale <- as.numeric(res$total["raw_alpha"])
    
    res$alpha.drop |>
      as_tibble(rownames = "item") |>
      filter(raw_alpha == max(raw_alpha)) |>
      select(item_to_drop = item, alpha_if_droppped = raw_alpha) |>
      mutate(alpha_full_scale = alpha_full_scale)
  }
  
  # apply item_to_delete_to_max_alpha to each half of (a subset of) a data set
  # optionally first sample just a subset of participants
  # then split in half and calculate the item to be dropped for each half
  # returns comparison of whether the item drop recommendation was the same in both halves
  alpha_by_split <- function(data = data, subset_n_per_split = NULL){
    
    dat <- data |>
      rownames_to_column(var = "id")
    
    if(is.numeric(subset_n_per_split)){
      dat <- dat |>
        sample_n(size = subset_n_per_split*2)
    } 
    
    data_split_1 <- dat |>
        sample_frac(size = 0.5)
    
    data_split_2 <- anti_join(dat, data_split_1, by = "id")
    
    item_drop_split_1 <- data_split_1 |>
      select(-id) |>
      item_to_delete_to_max_alpha() |>
      rename(split_1_item_to_drop      = item_to_drop,
             split_1_alpha_if_droppped = alpha_if_droppped,
             split_1_alpha_full_scale  = alpha_full_scale)
    
    item_drop_split_2 <- data_split_2 |>
      select(-id) |>
      item_to_delete_to_max_alpha() |>
      rename(split_2_item_to_drop      = item_to_drop,
             split_2_alpha_if_droppped = alpha_if_droppped,
             split_2_alpha_full_scale  = alpha_full_scale)

    res <- bind_cols(item_drop_split_1, item_drop_split_2) |>
      mutate(match = split_1_item_to_drop == split_2_item_to_drop,
             alpha_diff_full_scale = split_1_alpha_full_scale - split_2_alpha_full_scale)
    
    return(res)
  }
  
  # apply alpha_by_split() to nested data
  # apply it n_replications of times to each cell (i.e., nest)
  # summarize the proportion of replications in which the recommendation agreed between samples
  alpha_by_split_replicate <- function(data, subset_n_per_split, n_replications, ...){
    
    replications <-
      replicate(n = n_replications,
                alpha_by_split(data = data, subset_n_per_split = subset_n_per_split)$match)
    
    tibble(proportion         = mean(replications),
           variance           = var(replications),
           subset_n_per_split = subset_n_per_split,
           n_replications     = n_replications)
  }
  
  n_replications <- 1000
  
  # run analyses using the data
  results_nested <- data_nested_single_timepoint |>
    mutate(results_25 = furrr::future_map(data,
                                          alpha_by_split_replicate,
                                          subset_n_per_split = 25,
                                          n_replications = n_replications,
                                          .options = furrr_options(seed = TRUE)),
           results_50 = furrr::future_map(data,
                                          alpha_by_split_replicate,
                                          subset_n_per_split = 50,
                                          n_replications = n_replications,
                                          .options = furrr_options(seed = TRUE)),
           results_100 = furrr::future_map(data,
                                           alpha_by_split_replicate,
                                           subset_n_per_split = 100,
                                           n_replications = n_replications,
                                           .options = furrr_options(seed = TRUE)),
           results_200 = furrr::future_map(data,
                                           alpha_by_split_replicate,
                                           subset_n_per_split = 200,
                                           n_replications = n_replications,
                                           .options = furrr_options(seed = TRUE)),
           results_300 = furrr::future_map(data,
                                           alpha_by_split_replicate,
                                           subset_n_per_split = 300,
                                           n_replications = n_replications,
                                           .options = furrr_options(seed = TRUE)))
  
  # save to disk
  write_rds(results_nested, "../../data/results/results_nested.rds")
}

```

## Results

```{r}

data_reshaped <- results_nested |>
  unnest(results_25, results_50, results_100, results_200, results_300) |>
  select(scale,
         proportion_25  = proportion,
         proportion_50  = proportion1,
         proportion_100 = proportion2,
         proportion_200 = proportion3,
         proportion_300 = proportion4,
         variance_25    = variance,
         variance_50    = variance1,
         variance_100   = variance2,
         variance_200   = variance3,
         variance_300   = variance4) |>
  pivot_longer(names_to = c("type", "n_participants"), 
               names_pattern = "(.*)_(.*)",
               values_to = c("value"),
               cols = c("proportion_25", 
                        "proportion_50", 
                        "proportion_100", 
                        "proportion_200", 
                        "proportion_300",
                        "variance_25",
                        "variance_50",
                        "variance_100",
                        "variance_200",
                        "variance_300")) |>
  pivot_wider(names_from = "type", 
              values_from = "value") |>
  # offset problematic values, logit transform
  mutate(proportion = case_when(proportion == 0 ~ 0.001,
                                proportion == 1 ~ 0.999,
                                TRUE ~ proportion),
         proportion_logit = boot::logit(proportion),
         variance = ifelse(variance == 0, 0.001, variance)) |>
  # order factors
  mutate(n_participants = fct_reorder(n_participants, as.numeric(n_participants)))

```

## Meta

```{r}

# fit model
fit <-
  lmer(proportion_logit ~ 1 + n_participants + (1 | scale),
       weights = 1/variance,
       data = data_reshaped)

# extract re Tau
results_re_tau <- fit |>
  merTools::REsdExtract() |>
  as_tibble(rownames = "scale") |>
  rename(tau = value)

# extract marginal means
results <-
  summary(emmeans(fit, ~ n_participants)) |>
  dplyr::select(n_participants, estimate = emmean, se = SE, 
                ci_lower = lower.CL, ci_upper = upper.CL) |>
  mutate(pi_lower = estimate - (1.96 * sqrt(se^2 + results_re_tau$tau^2)),
         pi_upper = estimate + (1.96 * sqrt(se^2 + results_re_tau$tau^2))) |>
  select(-se) |>
  mutate_if(is.numeric, boot::inv.logit)

# plot
p_meta <-
  ggplot(results, aes(estimate, fct_rev(n_participants))) +
  geom_linerange(aes(xmin = pi_lower, xmax = pi_upper), size = 0.5, linetype = "dotted") +
  geom_linerange(aes(xmin = ci_lower, xmax = ci_upper)) +
  geom_point(size = 2.5) +
  mdthemes::md_theme_linedraw() +
  scale_x_continuous(breaks = c(0, .25, .5, .75, 1), 
                     labels = c("0.00<br/>(Worse)", "0.25", "0.50", "0.75", "1.00<br/>(Better)")) +
  labs(x = "Proportion replicated",
       y = "") +
  #theme(legend.position = "none") +
  xlim(0, 1)

p_meta

results |>
  round_df(2) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# # tests
# data_emms <- emmeans(fit, list(pairwise ~ n_participants), adjust = "holm")
# 
# summary(data_emms)$`pairwise differences of n_participants` |>
#   as.data.frame() |>
#   select(comparison = 1, p.value) |>
#   mutate(p.value = ifelse(p.value < .001, "< .001", round_half_up(p.value, 3))) |>
#   kable() |>
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# other

```{r}

reshaped |>
  ggplot(aes(n_participants, proportion)) +
  geom_point(aes(color = scale)) +
  geom_line(aes(color = scale)) +
  geom_smooth(method = "lm") +
  theme(legend.position = "none") +
  ylim(0,1)

reshaped |>
  group_by(n_participants) |>
  summarize(mean = mean(proportion),
            sd = sd(proportion),
            min = min(proportion),
            max = max(proportion)) |>
  round_df(2) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Session info

```{r}

sessionInfo()

```



