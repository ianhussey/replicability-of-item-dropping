---
title: "Assessing the replicability of item-dropping decisions based on Cronbach's-alpha-if-item-removed"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- NA

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(psych)
library(lme4)
library(sjPlot)
library(ggstance)
library(marginaleffects)
library(janitor)
library(boot)
library(Cairo)

# functions
# rounds all numeric variables in a dataframe to the desired number of places. Non-numeric variables will be ignored.
round_df <- function(df, digits) {
  mutate_if(df, is.numeric, janitor::round_half_up, digits = 2)
}

```

# Data

```{r}

data_nested_single_timepoint <- read_rds("../../data/processed/data_nested_single_timepoint.rds")

data_drop_decisions_no_data <- read_rds("../../data/processed/data_drop_decisions_no_data.rds") |>
  rename(sample_size = subset_n_per_split) |>
  mutate(sample_size                   = as.factor(sample_size),
         match_item_if_dropped         = as.factor(match_item_if_dropped),
         match_item_if_dropped_or_none = as.factor(match_item_if_dropped_or_none))

```

# Full sample metrics

These are already established scales, many of which are well known, with a reasonable range of Cronbach's $\alpha$ values when calculated in a large sample. The subsequent assessment of the replicability of item-dropping recommendations is therefore likely generalizable. 

```{r}

cronbachs_alpha <- function(data){
  psych::alpha(data)$total["raw_alpha"]
}

results_overall <- data_nested_single_timepoint |> 
  mutate(results = map(data, cronbachs_alpha)) |>
  unnest(results) |> 
  mutate(n = map(data, nrow)) |>
  unnest(n)

results_overall |>
  select(scale, alpha = raw_alpha, n) |>
  round_df(2) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

results_overall |>
  select(scale, alpha = raw_alpha, n) |>
  summarize(k_scales       = n(),
            N_participants = sum(n),
            alpha_min      = min(alpha),
            alpha_max      = max(alpha)) |>
  round_df(2) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

weighted_mean <- janitor::round_half_up(weighted.mean(results_overall$raw_alpha, results_overall$n), 2)

weighted_sd <- janitor::round_half_up(sqrt(Hmisc::wtd.var(results_overall$raw_alpha, results_overall$n)), 2)

```

Weighted mean $\alpha$ = `r weighted_mean`, weighted SD =  `r weighted_sd`.

# Frequency of item drop recommendations

```{r fig.height=12, fig.width=10}

data_n_items <- data_nested_single_timepoint |>
  mutate(n_items_in_scale = as.numeric(map(data, ncol))) |>
  select(-data)

data_drop_decisions_no_data |>
  distinct(scale, item_to_drop_a) |>
  count(scale) |>
  rename(n_distinct_items_with_drop_recommendations = n) |>
  left_join(data_n_items, by = "scale") |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

p_freq <- 
  data_drop_decisions_no_data |>
  count(scale, item_to_drop_a) |>
  arrange(scale, desc(n)) |>
  group_by(scale) |>
  mutate(item_rank = paste("ranked_item_", row_number(), sep = ""),
         item_rank = fct_reorder(item_rank, n, .desc = TRUE)) |>
  ungroup() |>
  select(-item_to_drop_a) |>
  ggplot(aes(item_rank, n)) +
  geom_bar(stat = "identity") +
  scale_x_discrete(labels = seq(from = 1, to = max(data_n_items$n_items_in_scale), by = 1)) +
  facet_wrap(~scale, ncol = 3) +
  xlab("Item ranked by number of drop recommendations") +
  ylab("Number of drop recommendations") +
  theme_light()

p_freq

ggsave(filename  = "../plots/plot_drop_recommendation_frequencies.pdf",
       plot      = p_freq,
       device    = "pdf",
       units     = "in",
       width     = 10,
       height    = 12,
       limitsize = TRUE)

```

# Replication rate of item-dropping recommendations

Using multilevel logistic models

Strategy 1: Drop one item based on max Cronbach's-$\alpha$-if-item-removed. I.e, item dropping was mandatory, even if the alpha in the retained items was lower than the full-scale $\alpha$. Recommendation in each sample could be item 1...item N.

Strategy 2: Drop an item based on max Cronbach's-$\alpha$-if-item-removed if it is higher than the full-scale $\alpha$. I.e, item dropping was not mandatory if it didn't improve $\alpha$. Recommendation in each sample could be item 1...item N or no item dropped.

```{r}

dat <- data_drop_decisions_no_data |>
  select(scale, replication, sample_size, match_item_if_dropped, match_item_if_dropped_or_none, sample_size, scale) |>
  pivot_longer(names_to = "strategy",
               values_to = "replicated",
               cols = c(match_item_if_dropped, match_item_if_dropped_or_none))

# fit model
fit <- 
  glmer(replicated ~ 1 + sample_size * strategy + (1 | scale),
        family = binomial(link = "logit"),
        data = dat)

# results table
tab_model(fit)

# marginal means
results_estimates <- fit |>
  marginalmeans(variables = c("sample_size", "strategy"), interaction = TRUE) |>
  select(sample_size, strategy, marginalmean, ci_lower = conf.low, ci_upper = conf.high)

```

## Plot

```{r fig.height=4, fig.width=6}

plot_replication <- 
  ggplot(results_estimates, aes(marginalmean, sample_size, color = strategy)) +
  geom_linerangeh(aes(xmin = ci_lower, xmax = ci_upper), position = position_dodge(width = 0.5)) +
  geom_point(size = 2.5, shape = 15, position = position_dodge(width = 0.5)) +
  scale_color_viridis_d(begin = 0.3, end = 0.7,
                        labels = c("Max \u03B1 if item removed",
                                   "Max \u03B1 if item removed<br/>if it improves \u03B1 compared to full scale"),
                        name = "Item dropping strategy") +
  scale_x_continuous(
    #breaks = c(0, .25, .5, .75, 1), 
    breaks = c(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0), 
    #labels = c("0.00<br/>(Worse)", "0.25", "0.50", "0.75", "1.00<br/>(Better)"),
    #labels = c("0.00", "0.25", "0.50", "0.75", "1.00"),
    #labels = c("0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1.0"),
    limits = c(0,1)
  ) +
  labs(x = "Replication rate",
       y = "Sample size") +
  mdthemes::md_theme_linedraw() +
  theme(legend.position = c(0.73, 0.18), # "right",
        legend.key.height = unit(0.05, 'npc'),
        panel.grid.minor.x = element_blank(),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black")) +
  guides(color = guide_legend(reverse = TRUE))

plot_replication

ggsave(filename  = "../plots/plot_replication_rate.pdf",
       plot      = plot_replication,
       device    = cairo_pdf, # for greek letters
       units     = "in",
       width     = 6,
       height    = 4,
       limitsize = TRUE)

```

## Table

```{r}

results_estimates |>
  round_df(2) |>
  arrange(sample_size, strategy) |>
  select(strategy, sample_size, marginalmean, ci_lower, ci_upper) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Session info

```{r}

sessionInfo()

```

